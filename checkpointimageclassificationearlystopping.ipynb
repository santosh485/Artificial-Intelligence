{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-02-08T12:09:43.382396Z","iopub.execute_input":"2022-02-08T12:09:43.383052Z","iopub.status.idle":"2022-02-08T12:09:44.056594Z","shell.execute_reply.started":"2022-02-08T12:09:43.382942Z","shell.execute_reply":"2022-02-08T12:09:44.055754Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n# import os\n\nnum_classes = 10\nimg_rows, img_cols = 256, 256\nbatch_size = 16\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_data_dir = '/kaggle/input/10-monkey-species/training/training/'\nvalidation_data_dir = '/kaggle/input/10-monkey-species/validation/validation/'\n\n# Let's use some data augmentaiton \ntrain_datagen = ImageDataGenerator(\n      rescale=1./255,\n      rotation_range=20,\n      width_shift_range=0.3,\n      height_shift_range=0.3,\n      horizontal_flip=True,\n      fill_mode='nearest')\n \nvalidation_datagen = ImageDataGenerator(rescale=1./255)\n \ntrain_generator = train_datagen.flow_from_directory(\n        train_data_dir,\n        target_size=(img_rows, img_cols),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=True)\n \nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_data_dir,\n        target_size=(img_rows, img_cols),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:18:33.537730Z","iopub.execute_input":"2022-02-08T13:18:33.538351Z","iopub.status.idle":"2022-02-08T13:18:33.774244Z","shell.execute_reply.started":"2022-02-08T13:18:33.538291Z","shell.execute_reply":"2022-02-08T13:18:33.773477Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\n# Padding = 'same'  results in padding the input such that\n# the output has the same length as the original input\nmodel.add(Conv2D(512, (3, 3), padding='same',\n                 input_shape= (img_rows, img_cols, 3)))\nmodel.add(Activation('relu'))\n\nmodel.add(Conv2D(256, (3, 3)))\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(128, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(16, (3, 3)))\nmodel.add(Activation('relu'))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\n\n#input layer\nmodel.add(Dense(units = 512, activation = 'relu'))\n#Hidden Layer\nmodel.add(Dense(units = 256, activation = 'relu'))\nmodel.add(Dense(units = 128, activation = 'relu'))\nmodel.add(Dense(units = 64, activation = 'relu'))\nmodel.add(Dense(units = 16, activation = 'relu'))\n\n\n\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))\n\n\n\nprint(model.summary())","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:19:20.609197Z","iopub.execute_input":"2022-02-08T13:19:20.609464Z","iopub.status.idle":"2022-02-08T13:19:20.804465Z","shell.execute_reply.started":"2022-02-08T13:19:20.609438Z","shell.execute_reply":"2022-02-08T13:19:20.803666Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"# checkpoint,early stoping,reduce_rl\nfrom keras import callbacks\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n\ncheckpoint = ModelCheckpoint(\n    'monkey.h5',monitor = 'val_loss',save_best_only = True,verbose = 1\n\n)\n\nearly_stoping = EarlyStopping(\n    monitor = 'val_loss',patience=5,min_delta = 0.0001,verbose=1,restore_best_weights=True\n)\n\nreduce_rl = ReduceLROnPlateau(\n    monitor = 'val_loss',factor = 0.1,patience = 5,verbose = 1,min_delta=0.0001\n)\ncallbacks = [early_stoping,checkpoint,reduce_rl]","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:19:55.418980Z","iopub.execute_input":"2022-02-08T13:19:55.419237Z","iopub.status.idle":"2022-02-08T13:19:55.425554Z","shell.execute_reply.started":"2022-02-08T13:19:55.419206Z","shell.execute_reply":"2022-02-08T13:19:55.424712Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"model.compile(loss = 'categorical_crossentropy',\n              optimizer = 'rmsprop',\n              metrics = ['accuracy'])\n\nnb_train_samples = 1098\nnb_validation_samples = 272\nepochs = 1\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = nb_train_samples // batch_size,\n    epochs = epochs,\n    callbacks = callbacks,\n    validation_data = validation_generator,\n    validation_steps = nb_validation_samples // batch_size)","metadata":{"execution":{"iopub.status.busy":"2022-02-08T13:20:14.434217Z","iopub.execute_input":"2022-02-08T13:20:14.434464Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}